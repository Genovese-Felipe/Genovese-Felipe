# ğŸ”“ SoluÃ§Ãµes Open Source para Notion + IA

## VisÃ£o Geral

Alternativas gratuitas e open source para integrar IA com Notion, sem depender de serviÃ§os pagos:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM Open     â”‚ -> â”‚ Self-Hosted  â”‚ -> â”‚   Notion     â”‚
â”‚ Source       â”‚    â”‚ ou Free API  â”‚    â”‚   (API)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸŒŸ OpÃ§Ãµes Gratuitas de LLMs

### 1. Groq (â­ Mais Recomendado)

**Por que Groq Ã© incrÃ­vel:**
- âœ… **Completamente gratuito** (sem cartÃ£o de crÃ©dito)
- âœ… **Extremamente rÃ¡pido** (tokens/segundo)
- âœ… **Modelos de qualidade**: LLaMA 3.1, Mixtral, Gemma
- âœ… **Rate limits generosos**: 30 req/min
- âœ… **API simples** (compatÃ­vel com OpenAI)

**Setup:**

```python
import os
from groq import Groq
from notion_client import Client

GROQ_API_KEY = os.getenv("GROQ_API_KEY")  # GrÃ¡tis em console.groq.com
NOTION_TOKEN = os.getenv("NOTION_TOKEN")
NOTION_PAGE_ID = os.getenv("NOTION_PAGE_ID")

groq_client = Groq(api_key=GROQ_API_KEY)
notion = Client(auth=NOTION_TOKEN)

def generate_with_groq(prompt, model="llama-3.1-70b-versatile"):
    """Gera conteÃºdo com Groq (GRÃTIS!)"""
    
    chat_completion = groq_client.chat.completions.create(
        messages=[
            {
                "role": "system",
                "content": "VocÃª cria conteÃºdo estruturado em Markdown para Notion."
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        model=model,
        temperature=0.7,
        max_tokens=8000,
        top_p=1,
        stream=False
    )
    
    return chat_completion.choices[0].message.content

def send_to_notion(content):
    """Envia para Notion"""
    blocks = []
    
    for paragraph in content.split('\n\n'):
        if paragraph.strip():
            blocks.append({
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [{"text": {"content": paragraph}}]
                }
            })
    
    notion.blocks.children.append(
        block_id=NOTION_PAGE_ID,
        children=blocks
    )

# Uso
prompt = "Crie um guia sobre produtividade com IA"
content = generate_with_groq(prompt)
send_to_notion(content)
```

**InstalaÃ§Ã£o:**
```bash
pip install groq notion-client python-dotenv
```

**Obter API Key:**
1. VÃ¡ para: https://console.groq.com/
2. Crie conta (grÃ¡tis, sem cartÃ£o)
3. VÃ¡ em "API Keys"
4. Crie uma nova key

**Modelos DisponÃ­veis (Gratuitos):**
- `llama-3.1-70b-versatile` - Melhor para tarefas gerais
- `llama-3.1-8b-instant` - Mais rÃ¡pido
- `mixtral-8x7b-32768` - Grande contexto
- `gemma2-9b-it` - Google Gemma

---

### 2. Hugging Face Inference API

**CaracterÃ­sticas:**
- âœ… Gratuito com rate limits
- âœ… Centenas de modelos disponÃ­veis
- âœ… Sem necessidade de GPU prÃ³pria

```python
import requests

HF_API_KEY = os.getenv("HF_API_KEY")  # GrÃ¡tis em huggingface.co

def generate_with_huggingface(prompt, model="meta-llama/Meta-Llama-3-8B-Instruct"):
    """Usa Hugging Face Inference API"""
    
    API_URL = f"https://api-inference.huggingface.co/models/{model}"
    
    headers = {"Authorization": f"Bearer {HF_API_KEY}"}
    
    payload = {
        "inputs": prompt,
        "parameters": {
            "max_new_tokens": 2000,
            "temperature": 0.7,
            "top_p": 0.95
        }
    }
    
    response = requests.post(API_URL, headers=headers, json=payload)
    return response.json()[0]['generated_text']

# Uso
content = generate_with_huggingface("Crie um artigo sobre IA")
send_to_notion(content)
```

**Obter Token:**
1. Criar conta em: https://huggingface.co/
2. Settings â†’ Access Tokens
3. Create new token

---

### 3. Ollama (Self-Hosted)

**Para rodar localmente:**

```bash
# Instalar Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Baixar modelo
ollama pull llama3.1

# Rodar modelo
ollama serve
```

**Python Integration:**

```python
import requests

def generate_with_ollama(prompt, model="llama3.1"):
    """Usa Ollama local"""
    
    url = "http://localhost:11434/api/generate"
    
    payload = {
        "model": model,
        "prompt": prompt,
        "stream": False
    }
    
    response = requests.post(url, json=payload)
    return response.json()['response']

# Uso
content = generate_with_ollama("Crie um tutorial de Python")
send_to_notion(content)
```

**Vantagens:**
- âœ… 100% gratuito
- âœ… Privacidade total
- âœ… Sem rate limits
- âœ… Offline

**Desvantagens:**
- âš ï¸ Requer hardware (RAM/GPU)
- âš ï¸ Setup mais complexo

---

### 4. Together AI

**Free Tier Generoso:**

```python
import together

together.api_key = os.getenv("TOGETHER_API_KEY")

def generate_with_together(prompt):
    """Usa Together AI (plano gratuito disponÃ­vel)"""
    
    response = together.Complete.create(
        prompt=prompt,
        model="meta-llama/Llama-3-70b-chat-hf",
        max_tokens=2000,
        temperature=0.7
    )
    
    return response['output']['choices'][0]['text']
```

---

## ğŸ¤– Plataformas de AutomaÃ§Ã£o Open Source

### 1. n8n (â­ Altamente Recomendado)

**O que Ã©:**
- Ferramenta de automaÃ§Ã£o visual (alternativa ao Zapier)
- 100% open source e gratuita
- Self-hosted ou cloud

**Setup:**

```bash
# Via Docker
docker run -it --rm \
  --name n8n \
  -p 5678:5678 \
  -v ~/.n8n:/home/node/.n8n \
  n8nio/n8n

# Ou via npm
npm install n8n -g
n8n start
```

**Criar Workflow n8n para Notion:**

1. **Trigger:** Webhook ou Cron
2. **HTTP Request:** Chamar Groq/HuggingFace API
3. **Function:** Processar resposta
4. **Notion Node:** Criar/atualizar pÃ¡gina

**Exemplo de Workflow JSON:**

```json
{
  "nodes": [
    {
      "name": "Cron",
      "type": "n8n-nodes-base.cron",
      "parameters": {
        "triggerTimes": {
          "item": [
            {
              "hour": 9,
              "minute": 0
            }
          ]
        }
      }
    },
    {
      "name": "Groq API",
      "type": "n8n-nodes-base.httpRequest",
      "parameters": {
        "url": "https://api.groq.com/openai/v1/chat/completions",
        "method": "POST",
        "jsonParameters": true,
        "options": {},
        "bodyParametersJson": "{\n  \"model\": \"llama-3.1-70b-versatile\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"Crie um resumo diÃ¡rio de tecnologia\"\n    }\n  ]\n}"
      }
    },
    {
      "name": "Notion",
      "type": "n8n-nodes-base.notion",
      "parameters": {
        "resource": "page",
        "operation": "create",
        "pageId": "YOUR_PAGE_ID"
      }
    }
  ],
  "connections": {
    "Cron": {
      "main": [[{ "node": "Groq API" }]]
    },
    "Groq API": {
      "main": [[{ "node": "Notion" }]]
    }
  }
}
```

**Recursos:**
- ğŸ“– Docs: https://docs.n8n.io/
- ğŸ“ Templates: https://n8n.io/workflows/

---

### 2. Activepieces

**Similar ao n8n, mas com foco em facilidade:**

```bash
# Via Docker
docker run -p 8080:80 activepieces/activepieces
```

**Features:**
- Interface mais simples que n8n
- IntegraÃ§Ã£o nativa com Notion
- Templates prontos

---

### 3. Pipedream

**Free Tier:**
- 333 credits/mÃªs gratuitos
- Serverless (nÃ£o precisa hospedar)

```javascript
// Pipedream Workflow
export default defineComponent({
  async run({ steps, $ }) {
    // 1. Gerar conteÃºdo com Groq
    const groqResponse = await axios.post(
      'https://api.groq.com/openai/v1/chat/completions',
      {
        model: 'llama-3.1-70b-versatile',
        messages: [{ role: 'user', content: 'Crie conteÃºdo' }]
      },
      {
        headers: { 'Authorization': `Bearer ${process.env.GROQ_API_KEY}` }
      }
    );
    
    // 2. Enviar para Notion
    await axios.patch(
      `https://api.notion.com/v1/blocks/${process.env.NOTION_PAGE_ID}/children`,
      {
        children: [
          {
            object: 'block',
            type: 'paragraph',
            paragraph: {
              rich_text: [{
                text: { content: groqResponse.data.choices[0].message.content }
              }]
            }
          }
        ]
      },
      {
        headers: {
          'Authorization': `Bearer ${process.env.NOTION_TOKEN}`,
          'Notion-Version': '2022-06-28'
        }
      }
    );
  }
});
```

---

## ğŸ“¦ Ferramentas e Bibliotecas

### 1. LangChain (Open Source)

**Framework para LLM applications:**

```python
from langchain_groq import ChatGroq
from langchain_community.document_loaders import NotionDBLoader
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

# Setup
llm = ChatGroq(
    groq_api_key=GROQ_API_KEY,
    model_name="llama-3.1-70b-versatile"
)

# Template
template = """
Crie conteÃºdo estruturado sobre: {topic}

Formato: Markdown
SeÃ§Ãµes: 3-5
Estilo: Profissional e informativo
"""

prompt = PromptTemplate(template=template, input_variables=["topic"])
chain = LLMChain(llm=llm, prompt=prompt)

# Gerar e enviar para Notion
content = chain.run(topic="IA no trabalho")
send_to_notion(content)
```

**InstalaÃ§Ã£o:**
```bash
pip install langchain langchain-groq
```

---

### 2. LlamaIndex (Open Source)

**Para RAG (Retrieval-Augmented Generation):**

```python
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader
from llama_index.llms.groq import Groq

# Setup LLM
llm = Groq(model="llama-3.1-70b-versatile", api_key=GROQ_API_KEY)

# Carregar documentos
documents = SimpleDirectoryReader("data").load_data()

# Criar Ã­ndice
index = VectorStoreIndex.from_documents(documents, llm=llm)

# Query
query_engine = index.as_query_engine()
response = query_engine.query("Resuma estes documentos")

# Enviar para Notion
send_to_notion(str(response))
```

---

### 3. AutoGen (Microsoft - Open Source)

**Para agentes autÃ´nomos:**

```python
import autogen

config_list = [
    {
        "model": "llama-3.1-70b-versatile",
        "api_key": GROQ_API_KEY,
        "base_url": "https://api.groq.com/openai/v1"
    }
]

# Criar assistente
assistant = autogen.AssistantAgent(
    name="assistant",
    llm_config={"config_list": config_list}
)

# Criar usuÃ¡rio proxy
user_proxy = autogen.UserProxyAgent(
    name="user",
    human_input_mode="NEVER",
    code_execution_config={"work_dir": "coding"}
)

# Iniciar conversa
user_proxy.initiate_chat(
    assistant,
    message="Crie um artigo sobre automaÃ§Ã£o e salve em Markdown"
)
```

---

## ğŸ”§ Projetos Completos Open Source

### 1. Notionize (GitHub)

**Ferramenta open source para Notion:**
- Clone: https://github.com/yourusername/notionize
- Recursos: Templates, automaÃ§Ãµes, integraÃ§Ãµes

### 2. Notion-AI-Bridge (Exemplo)

```python
# notion_ai_bridge.py
class NotionAIBridge:
    def __init__(self, llm_provider="groq"):
        self.llm_provider = llm_provider
        self.notion = Client(auth=NOTION_TOKEN)
    
    def generate_and_send(self, prompt, page_id):
        # Gerar com LLM escolhido
        if self.llm_provider == "groq":
            content = generate_with_groq(prompt)
        elif self.llm_provider == "ollama":
            content = generate_with_ollama(prompt)
        
        # Enviar para Notion
        self.send_to_notion(content, page_id)
    
    def send_to_notion(self, content, page_id):
        # ImplementaÃ§Ã£o...
        pass

# Uso
bridge = NotionAIBridge(llm_provider="groq")
bridge.generate_and_send(
    "Crie um plano de estudos",
    page_id=NOTION_PAGE_ID
)
```

---

## ğŸ’° ComparaÃ§Ã£o de Custos

| SoluÃ§Ã£o | Custo Mensal | Rate Limits | Qualidade |
|---------|--------------|-------------|-----------|
| **Groq** | ğŸ’š $0 | 30 req/min | â­â­â­â­ |
| **HuggingFace** | ğŸ’š $0 | 1000 req/dia | â­â­â­ |
| **Ollama** | ğŸ’š $0 | Ilimitado | â­â­â­â­ |
| **Together AI** | ğŸ’š $0* | 60 req/min | â­â­â­â­ |
| **n8n** | ğŸ’š $0 | Ilimitado | - |
| **Pipedream** | ğŸ’š $0* | 333 credits | - |

*Free tier disponÃ­vel

---

## ğŸ¯ Stack Recomendada (100% Gratuita)

### Setup Ideal:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Groq (LLM gratuito e rÃ¡pido)            â”‚
â”‚  2. n8n (AutomaÃ§Ã£o open source)             â”‚
â”‚  3. Notion API (Workspace Plus)             â”‚
â”‚  4. Python Scripts (CustomizaÃ§Ã£o)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Por que:**
- âœ… Custo zero
- âœ… Sem vendor lock-in
- âœ… MÃ¡xima flexibilidade
- âœ… Privacidade controlada

---

## ğŸ“‹ Checklist de ImplementaÃ§Ã£o

### OpÃ§Ã£o 1: Quick Start (1 hora)
- [ ] Criar conta no Groq
- [ ] Obter API key (grÃ¡tis)
- [ ] Instalar `groq` e `notion-client`
- [ ] Rodar script exemplo
- [ ] Testar geraÃ§Ã£o de conteÃºdo

### OpÃ§Ã£o 2: Setup Completo (1 dia)
- [ ] Setup Groq + Notion
- [ ] Instalar n8n via Docker
- [ ] Criar workflows bÃ¡sicos
- [ ] Configurar automaÃ§Ãµes
- [ ] Documentar processos

### OpÃ§Ã£o 3: Self-Hosted (2-3 dias)
- [ ] Instalar Ollama
- [ ] Baixar modelos LLaMA
- [ ] Setup n8n self-hosted
- [ ] Criar scripts personalizados
- [ ] Configurar backups

---

## ğŸš€ Exemplos PrÃ¡ticos

### 1. Daily Digest AutomÃ¡tico

```python
# daily_digest.py
import schedule
import time

def create_daily_digest():
    topics = [
        "Ãšltimas notÃ­cias em tecnologia",
        "TendÃªncias de IA",
        "Dicas de produtividade"
    ]
    
    for topic in topics:
        prompt = f"Resuma em 2 parÃ¡grafos: {topic}"
        content = generate_with_groq(prompt)
        send_to_notion(content)
        time.sleep(2)  # Rate limiting

# Agendar para 9h todos os dias
schedule.every().day.at("09:00").do(create_daily_digest)

while True:
    schedule.run_pending()
    time.sleep(60)
```

### 2. Content Generator

```python
def generate_blog_post(topic, tone="professional"):
    prompt = f"""
    Crie um artigo de blog sobre: {topic}
    Tom: {tone}
    
    Estrutura:
    - IntroduÃ§Ã£o cativante
    - 3 seÃ§Ãµes principais com subtÃ³picos
    - ConclusÃ£o com call-to-action
    - Formato: Markdown
    """
    
    content = generate_with_groq(prompt, model="llama-3.1-70b-versatile")
    send_to_notion(content)
    
    return "âœ… Artigo criado e enviado ao Notion!"
```

### 3. Research Assistant

```python
def research_and_summarize(topic):
    # 1. Gerar outline
    outline_prompt = f"Crie um outline para pesquisar sobre: {topic}"
    outline = generate_with_groq(outline_prompt)
    
    # 2. Para cada seÃ§Ã£o, gerar conteÃºdo
    sections = outline.split('\n')
    full_content = []
    
    for section in sections:
        if section.strip():
            section_prompt = f"Desenvolva em 2 parÃ¡grafos: {section}"
            section_content = generate_with_groq(section_prompt)
            full_content.append(section_content)
            time.sleep(2)
    
    # 3. Enviar para Notion
    final_content = '\n\n'.join(full_content)
    send_to_notion(final_content)
```

---

## ğŸ”— Recursos Adicionais

- ğŸŒ **Groq**: https://console.groq.com/
- ğŸ¤— **Hugging Face**: https://huggingface.co/
- ğŸ¦™ **Ollama**: https://ollama.com/
- ğŸ”§ **n8n**: https://n8n.io/
- ğŸ“š **LangChain**: https://python.langchain.com/
- ğŸ¦œ **LlamaIndex**: https://www.llamaindex.ai/

---

## PrÃ³ximos Passos

- â†’ **[AutomaÃ§Ãµes No-Code](06-Automacoes-Zapier-Make.md)**
- â†’ **[Scripts de Exemplo](07-Scripts-Exemplos/)**
- â†’ **[Templates de Workflows](08-Templates-Workflows/)**
